{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello everybody üòÉ üòÉ welcome back\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Image Size\n",
    "IMG_ROWS, IMG_COLS = 100, 100 # input image dimensions\n",
    "NB_CLASSES =  10 # number of outputs = number of digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (01)   ACQUISITION DES DONNEES - IMAGES DES FEUILLES DES PLANTES. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################### function for plotting images\n",
    "\n",
    "def plot_images(images, total_images=100, rows=20, cols=5, fsize=(20,100), titre='Image'):\n",
    "    \n",
    "    fig = plt.figure(figsize=fsize) # create a new figure window\n",
    "    \n",
    "    for i in range(total_images): # display images\n",
    "        # subplot : 33 rows and 5 columns\n",
    "        img_grid = fig.add_subplot(rows, cols, i+1)\n",
    "        # plot features as image\n",
    "        img_grid.imshow(images[i])\n",
    "        \n",
    "        plt.title(titre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ function for resizng images\n",
    "       \n",
    "def preprocess_image(image, image_height=IMG_ROWS, image_width=IMG_COLS):\n",
    "\n",
    "    return cv2.resize(image, (image_height, image_width))\n",
    "\n",
    "############################################ function for reading images \n",
    "       \n",
    "def read_images (path , sz= None ):\n",
    "    \n",
    "    print('\\nCHARGEMENT DES IMAGES DE LA BASE .......................!\\n') \n",
    "\n",
    "    X,y = [], []\n",
    "    \n",
    "    for dirname , dirnames , filenames in os.walk(path):\n",
    "        \n",
    "        c = 0\n",
    "        \n",
    "        for subdirname in dirnames :\n",
    "            \n",
    "            subject_path = os. path . join ( dirname , subdirname )\n",
    "            \n",
    "            for filename in os. listdir ( subject_path ):\n",
    "                \n",
    "                im = Image.open(os.path.join(subject_path, filename))\n",
    "                #im = im.convert (\"L\")\n",
    "\n",
    "                if (sz is not None ):\n",
    "                    im = im.resize (sz , Image.ANTIALIAS ) \n",
    "                    \n",
    "                im = np.array(im)\n",
    "                im = preprocess_image(im, IMG_ROWS, IMG_COLS)\n",
    "                X.append(im)\n",
    "                y.append (c)  \n",
    "                \n",
    "            c = c+1\n",
    "            \n",
    "    return [X,y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Read And Resize test images\n",
    "\n",
    "print('\\n\\nLECTURE DES IMAGES DE LA BASE D\\'APPRENTISSAGE........!') \n",
    "\n",
    "[X_train, y_train] = read_images(\"C:/Users/Dell 7280/Documents/Etude/ESCEP/S3/Deep learning/Corrections/TP4-Tomato/Data/TrainData\") # Tomato\n",
    "\n",
    "print('\\nAFFICHAGE DE QUELQUES IMAGES DE LA BASE.................!')\n",
    "plot_images(X_train, 2, 1, 2,(10, 50), titre='Base D\\'Apprentissage')\n",
    "plt.show()\n",
    "print('\\nFIN D\\'AFFICHAGE DES IMAGES DE LA BASE...................!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################# Train Data\n",
    "\n",
    "images_train = X_train\n",
    "images_train = np.asarray(images_train)\n",
    "\n",
    "# Train targets\n",
    "train_features = images_train\n",
    "train_targets = y_train\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "# convert class vectors to binary class matrices\n",
    "train_targets = to_categorical(train_targets, NB_CLASSES)\n",
    "\n",
    "print('\\nNORMALISATION DES BASES DE TEST ET D\\'APPRENTISSAGE.\\n')\n",
    "\n",
    "########################################################## Normalisation\n",
    "\n",
    "train_features = train_features.astype('float32')\n",
    "\n",
    "mean_vals = np.mean(train_features, axis=0)\n",
    "std_val = np.std(train_features)\n",
    "train_features = (train_features - mean_vals)/std_val\n",
    "\n",
    "train_features = train_features.reshape(train_features.shape[0], IMG_ROWS, IMG_COLS, 3)\n",
    "print(\"train_features.shape     >==============<> : {}\".format(train_features.shape))\n",
    "print(\"train_targets.shape      >==============<> : {}\".format(train_targets.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "#(02)        CLASSIFICATION : CREATION DU MODELE DE PREDICTION         #\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import concatenate\n",
    "from keras.applications import DenseNet121\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras import backend as K\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, AveragePooling2D, GlobalAveragePooling2D, Dense, MaxPooling2D, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def dense_block(x, blocks, name):\n",
    "    for i in range(blocks):\n",
    "        x = conv_block(x, 32, name=name + '_block' + str(i + 1))\n",
    "    return x\n",
    "\n",
    "def transition_block(x, reduction, name):\n",
    "    x = BatchNormalization(axis=-1, epsilon=1.001e-5, name=name + '_bn')(x)\n",
    "    x = Activation('relu', name=name + '_relu')(x)\n",
    "    x = Conv2D(int(x.shape[-1] * reduction), 1, use_bias=False, name=name + '_conv')(x)\n",
    "    x = AveragePooling2D(2, strides=2, name=name + '_pool')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(x, growth_rate, name):\n",
    "    x1 = BatchNormalization(axis=-1, epsilon=1.001e-5, name=name + '_0_bn')(x)\n",
    "    x1 = Activation('relu', name=name + '_0_relu')(x1)\n",
    "    x1 = Conv2D(4 * growth_rate, 1, use_bias=False, name=name + '_1_conv')(x1)\n",
    "    x1 = BatchNormalization(axis=-1, epsilon=1.001e-5, name=name + '_1_bn')(x1)\n",
    "    x1 = Activation('relu', name=name + '_1_relu')(x1)\n",
    "    x1 = Conv2D(growth_rate, 3, padding='same', use_bias=False, name=name + '_2_conv')(x1)\n",
    "    x = concatenate([x, x1], axis=-1, name=name + '_concat')\n",
    "    return x\n",
    "\n",
    "def DenseNet(input_shape, classes):\n",
    "    img_input = Input(shape=input_shape)\n",
    "    x = Conv2D(64, 7, strides=2, use_bias=False, padding='same', name='conv1/conv')(img_input)\n",
    "    x = BatchNormalization(axis=-1, epsilon=1.001e-5, name='conv1/bn')(x)\n",
    "    x = Activation('relu', name='conv1/relu')(x)\n",
    "    x = MaxPooling2D(3, strides=2, padding='same', name='pool1')(x)\n",
    "\n",
    "    x = dense_block(x, blocks=6, name='conv2')\n",
    "    x = transition_block(x, 0.5, name='pool2')\n",
    "    x = dense_block(x, blocks=12, name='conv3')\n",
    "    x = transition_block(x, 0.5, name='pool3')\n",
    "    x = dense_block(x, blocks=24, name='conv4')\n",
    "    x = transition_block(x, 0.5, name='pool4')\n",
    "    x = dense_block(x, blocks=16, name='conv5')\n",
    "\n",
    "    x = BatchNormalization(axis=-1, epsilon=1.001e-5, name='bn')(x)\n",
    "    x = Activation('relu', name='relu')(x)\n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = Dense(classes, activation='softmax', name='fc')(x)\n",
    "\n",
    "    model = Model(inputs=img_input, outputs=x, name='densenet')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finition de l'optimiseur et des param√®tres\n",
    "OPTIMIZER = Adam()\n",
    "IMG_ROWS, IMG_COLS = 64, 64  # Mettez les dimensions correctes de vos images ici\n",
    "INPUT_SHAPE = (IMG_ROWS, IMG_COLS, 3)\n",
    "NB_CLASSES = 1000  # Changez ceci selon votre nombre de classes\n",
    "NB_EPOCH = 50\n",
    "BATCH_SIZE = 64\n",
    "VERBOSE = 1\n",
    "\n",
    "# Redimensionnement des donn√©es d'entr√©e\n",
    "def resize_images(images, target_size):\n",
    "    resized_images = np.zeros((images.shape[0], *target_size, 3))\n",
    "    for i, img in enumerate(images):\n",
    "        resized_images[i] = np.resize(img, (*target_size, 3))\n",
    "    return resized_images\n",
    "\n",
    "# Charger et redimensionner les images d'entra√Ænement\n",
    "train_features = resize_images(np.asarray(X_train), (IMG_ROWS, IMG_COLS))\n",
    "\n",
    "# Convertir les √©tiquettes en matrices de classe binaires\n",
    "train_targets = to_categorical(np.asarray(y_train), NB_CLASSES)\n",
    "\n",
    "print('\\nNORMALISATION DES BASES DE TEST ET D\\'APPRENTISSAGE.\\n')\n",
    "\n",
    "# Normalisation des donn√©es\n",
    "train_features = train_features.astype('float32')\n",
    "mean_vals = np.mean(train_features, axis=0)\n",
    "std_val = np.std(train_features)\n",
    "train_features = (train_features - mean_vals) / std_val\n",
    "\n",
    "# V√©rifiez les dimensions des donn√©es\n",
    "print(\"train_features.shape     >==============<> : {}\".format(train_features.shape))\n",
    "print(\"train_targets.shape      >==============<> : {}\".format(train_targets.shape))\n",
    "\n",
    "def build_densenet(input_shape, classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(64, kernel_size=7, strides=2, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=2, strides=2, padding='same')(x)\n",
    "    # Ajoutez les couches suppl√©mentaires pour votre mod√®le ResNet ici\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    outputs = Dense(classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Construction et compilation du mod√®le ResNet\n",
    "model = build_densenet(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "model.compile(optimizer=OPTIMIZER, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Affichage du r√©sum√© du mod√®le\n",
    "model.summary()\n",
    "\n",
    "# Enregistrement du temps de d√©but d'entra√Ænement\n",
    "t_start = time.time()\n",
    "\n",
    "# Entra√Ænement du mod√®le\n",
    "history = model.fit(train_features, train_targets, batch_size=BATCH_SIZE, epochs=NB_EPOCH, verbose=VERBOSE)\n",
    "\n",
    "# Calcul du temps total d'entra√Ænement\n",
    "time_full_train = time.time() - t_start\n",
    "\n",
    "# Affichage du temps d'entra√Ænement\n",
    "print(\"\\nTEMPS D'APPRENTISSAGE DU CLASSIFIEUR >====<> : %0.2fs \" % (time_full_train))\n",
    "\n",
    "# Sauvegarde du mod√®le entra√Æn√©\n",
    "model.save(\"DenseNet_groupe_2.h5\")\n",
    "print('\\nENREGISTRER LE MODELE .\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membre du groupe N¬∞2:\n",
    "\n",
    "\n",
    "ISSA IBRAHIM Moubarak\n",
    "\n",
    "Abdourahamen bachir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
